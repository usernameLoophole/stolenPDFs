{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e39XnwwQ5jgF",
        "outputId": "34e3c2d5-84d3-424a-eb8c-cc06f1bdcad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum channel length across all channels: 126281 samples\n",
            "Extracting 1261 windows of length 200 each (with step size 100).\n",
            "Channel [0]: L5_accx.csv\n",
            "Channel [1]: L5_accy.csv\n",
            "Channel [2]: L5_accz.csv\n",
            "Channel [3]: L5_gyry.csv\n",
            "Channel [4]: L5_gyrz.csv\n",
            "Channel [5]: l5_gyrx.csv\n",
            "Channel [6]: RT_accx.csv\n",
            "Channel [7]: RT_accy.csv\n",
            "Channel [8]: RT_accz.csv\n",
            "Channel [9]: RT_gyrx.csv\n",
            "Channel [10]: RT_gyry.csv\n",
            "Channel [11]: RT_gyrz.csv\n",
            "Channel [12]: ML_accx.csv\n",
            "Channel [13]: ML_accy.csv\n",
            "Channel [14]: ML_accz.csv\n",
            "Channel [15]: ML_gyrx.csv\n",
            "Channel [16]: ML_gyry.csv\n",
            "Channel [17]: ML_gyrz.csv\n",
            "Processed data shape: (18, 1261, 200)\n",
            "Computing synthetic channel (rotation difference) using channels 11 (RT_gyrz.csv) and 17 (ML_gyrz.csv).\n",
            "New data shape after adding synthetic rotation difference channel: (19, 1261, 200)\n",
            "Minimum channel length across all channels: 35397 samples\n",
            "Extracting 352 windows of length 200 each (with step size 100).\n",
            "Channel [0]: L5_accx.csv\n",
            "Channel [1]: L5_accy.csv\n",
            "Channel [2]: L5_accz.csv\n",
            "Channel [3]: L5_gyrx.csv\n",
            "Channel [4]: L5_gyry.csv\n",
            "Channel [5]: L5_gyrz.csv\n",
            "Channel [6]: RT_accx.csv\n",
            "Channel [7]: RT_accy.csv\n",
            "Channel [8]: RT_accz.csv\n",
            "Channel [9]: RT_gyrx.csv\n",
            "Channel [10]: RT_gyry.csv\n",
            "Channel [11]: RT_gyrz.csv\n",
            "Channel [12]: ML_accx.csv\n",
            "Channel [13]: ML_accy.csv\n",
            "Channel [14]: ML_accz.csv\n",
            "Channel [15]: ML_gyrx.csv\n",
            "Channel [16]: ML_gyry.csv\n",
            "Channel [17]: ML_gyrz.csv\n",
            "Processed data shape: (18, 352, 200)\n",
            "Computing synthetic channel (rotation difference) using channels 11 (RT_gyrz.csv) and 17 (ML_gyrz.csv).\n",
            "New data shape after adding synthetic rotation difference channel: (19, 352, 200)\n",
            "\n",
            "Final Healthy Dataset Channels: ['L5_accx.csv', 'L5_accy.csv', 'L5_accz.csv', 'L5_gyry.csv', 'L5_gyrz.csv', 'l5_gyrx.csv', 'RT_accx.csv', 'RT_accy.csv', 'RT_accz.csv', 'RT_gyrx.csv', 'RT_gyry.csv', 'RT_gyrz.csv', 'ML_accx.csv', 'ML_accy.csv', 'ML_accz.csv', 'ML_gyrx.csv', 'ML_gyry.csv', 'ML_gyrz.csv', 'Synthetic_RotationDiff_RT_gyrz.csv_ML_gyrz.csv']\n",
            "Final Injury Dataset Channels: ['L5_accx.csv', 'L5_accy.csv', 'L5_accz.csv', 'L5_gyrx.csv', 'L5_gyry.csv', 'L5_gyrz.csv', 'RT_accx.csv', 'RT_accy.csv', 'RT_accz.csv', 'RT_gyrx.csv', 'RT_gyry.csv', 'RT_gyrz.csv', 'ML_accx.csv', 'ML_accy.csv', 'ML_accz.csv', 'ML_gyrx.csv', 'ML_gyry.csv', 'ML_gyrz.csv', 'Synthetic_RotationDiff_RT_gyrz.csv_ML_gyrz.csv']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m1,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m1,552\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)               │             \u001b[38;5;34m392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling1d_2 (\u001b[38;5;33mUpSampling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling1d_3 (\u001b[38;5;33mUpSampling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m1,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │           \u001b[38;5;34m1,843\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,843</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,611\u001b[0m (29.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,611</span> (29.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,611\u001b[0m (29.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,611</span> (29.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainData shape: (1261, 200, 19)\n",
            "testData shape: (352, 200, 19)\n",
            "Epoch 1/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.0287 - val_loss: 0.0199\n",
            "Epoch 2/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 3/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0143 - val_loss: 0.0144\n",
            "Epoch 4/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0101 - val_loss: 0.0114\n",
            "Epoch 5/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0077 - val_loss: 0.0101\n",
            "Epoch 6/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0067 - val_loss: 0.0100\n",
            "Epoch 7/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - val_loss: 0.0100\n",
            "Epoch 8/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0057 - val_loss: 0.0097\n",
            "Epoch 9/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0053 - val_loss: 0.0098\n",
            "Epoch 10/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - val_loss: 0.0099\n",
            "Epoch 11/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0048 - val_loss: 0.0097\n",
            "Epoch 12/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0045 - val_loss: 0.0097\n",
            "Epoch 13/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0095\n",
            "Epoch 14/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0098\n",
            "Epoch 15/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0097\n",
            "Epoch 16/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0095\n",
            "Epoch 17/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0038 - val_loss: 0.0094\n",
            "Epoch 18/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0092\n",
            "Epoch 19/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0090\n",
            "Epoch 20/20\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0035 - val_loss: 0.0088\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\n",
            "--- Input Distance Analysis ---\n",
            "Average reconstruction error on training data: 0.0035\n",
            "Average reconstruction error on input data:    0.0088\n",
            "Input distance score (relative to training data): 1.5521\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Channel 0 (L5_accx.csv) importance: -0.0001\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Channel 1 (L5_accy.csv) importance: -0.0001\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Channel 2 (L5_accz.csv) importance: 0.0001\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 3 (L5_gyrx.csv) importance: 0.0001\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 4 (L5_gyry.csv) importance: -0.0002\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 5 (L5_gyrz.csv) importance: -0.0000\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 6 (RT_accx.csv) importance: 0.0004\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 7 (RT_accy.csv) importance: 0.0000\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 8 (RT_accz.csv) importance: 0.0001\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 9 (RT_gyrx.csv) importance: 0.0014\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 10 (RT_gyry.csv) importance: 0.0004\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Channel 11 (RT_gyrz.csv) importance: 0.0014\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import matplotlib.pyplot as plt  # For plotting\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D\n",
        "\n",
        "def fetch_csv_files(user, repo, folder):\n",
        "\n",
        "    url = f\"https://api.github.com/repos/{user}/{repo}/contents/{folder}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Error fetching folder '{folder}': {response.status_code}\")\n",
        "\n",
        "    files = sorted(response.json(), key=lambda x: x['name'])\n",
        "\n",
        "    channel_data_list = []\n",
        "    channel_names = []\n",
        "\n",
        "    for file_info in files:\n",
        "        if file_info['name'].endswith('.csv'):\n",
        "            download_url = file_info['download_url']\n",
        "            file_response = requests.get(download_url)\n",
        "            if file_response.status_code != 200:\n",
        "                raise Exception(f\"Error downloading file {file_info['name']}\")\n",
        "\n",
        "            # Use header=0 to indicate the first row is the header\n",
        "            df = pd.read_csv(StringIO(file_response.text), header=0)\n",
        "            channel_data = df.values.flatten()\n",
        "            channel_data_list.append(channel_data)\n",
        "            channel_names.append(file_info['name'])\n",
        "\n",
        "    return channel_data_list, channel_names\n",
        "\n",
        "def sliding_window(data, window_size, step):\n",
        "\n",
        "    windows = []\n",
        "    for start in range(0, len(data) - window_size + 1, step):\n",
        "        window = data[start:start+window_size]\n",
        "        windows.append(window)\n",
        "    return np.array(windows)\n",
        "\n",
        "def load_and_preprocess(user, repo, N, K):\n",
        "\n",
        "    folders = ['L5', 'LEG', 'ML']\n",
        "\n",
        "    channels = []\n",
        "    channel_names = []\n",
        "\n",
        "    for folder in folders:\n",
        "        ch_data, ch_names = fetch_csv_files(user, repo, folder)\n",
        "        channels.extend(ch_data)\n",
        "        channel_names.extend(ch_names)\n",
        "\n",
        "    if len(channels) == 0:\n",
        "        raise ValueError(\"No CSV files were found in the specified repository folders.\")\n",
        "\n",
        "    # Find shortest channel length\n",
        "    lengths = [len(ch) for ch in channels]\n",
        "    T = min(lengths)\n",
        "    print(f\"Minimum channel length across all channels: {T} samples\")\n",
        "\n",
        "    if T < N:\n",
        "        raise ValueError(f\"Not enough samples in channels. Required window size is {N}, \"\n",
        "                         f\"but the shortest channel has only {T} samples.\")\n",
        "\n",
        "    truncated_channels = [ch[:T] for ch in channels]\n",
        "\n",
        "    # Compute step size from overlap ratio\n",
        "    step = int(N * (1 - K))\n",
        "    if step <= 0:\n",
        "        raise ValueError(\"Step size computed from N and K must be positive.\")\n",
        "\n",
        "    # Compute number of windows (W) after truncation\n",
        "    W = (T - N) // step + 1\n",
        "    print(f\"Extracting {W} windows of length {N} each (with step size {step}).\")\n",
        "\n",
        "    # Process each truncated channel: extract sliding windows\n",
        "    processed_channels = []\n",
        "    for idx, ch in enumerate(truncated_channels):\n",
        "        windows = sliding_window(ch, N, step)\n",
        "        if windows.shape[0] != W:\n",
        "            raise ValueError(f\"Channel {idx} ({channel_names[idx]}) produced {windows.shape[0]} windows, but expected {W}.\")\n",
        "        processed_channels.append(windows)\n",
        "        print(f\"Channel [{idx}]: {channel_names[idx]}\")  # Print channel index & name\n",
        "\n",
        "    processed_data = np.stack(processed_channels, axis=0)\n",
        "    print(f\"Processed data shape: {processed_data.shape}\")\n",
        "\n",
        "    return processed_data, channel_names\n",
        "\n",
        "#def add_synthetic_channel(data, ch1_idx, ch2_idx, channel_names):\n",
        "\n",
        "#    num_channels, num_windows, num_samples = data.shape\n",
        "#\n",
        "#    if ch1_idx >= num_channels or ch2_idx >= num_channels:\n",
        "#        raise ValueError(f\"Channel indices out of range. Data has {num_channels} channels.\")\n",
        "#\n",
        "#    print(f\"Computing synthetic channel using absolute differences between channels {ch1_idx} ({channel_names[ch1_idx]}) and {ch2_idx} ({channel_names[ch2_idx]}).\")\n",
        "#\n",
        "#    # Compute absolute difference between selected channels\n",
        "#    synthetic_channel = np.abs(data[ch1_idx].astype(float) - data[ch2_idx].astype(float))\n",
        "#\n",
        "#    # Append to the existing dataset\n",
        "#    updated_data = np.vstack([data, np.expand_dims(synthetic_channel, axis=0)])\n",
        "#    channel_names.append(f\"Synthetic_{channel_names[ch1_idx]}_{channel_names[ch2_idx]}\")\n",
        "#\n",
        "#    print(f\"New data shape after adding synthetic channel: {updated_data.shape}\")\n",
        "#    return updated_data, channel_names\n",
        "\n",
        "def add_synthetic_channel(data, ch1_idx, ch2_idx, channel_names, dt):\n",
        "\n",
        "    num_channels, num_windows, num_samples = data.shape\n",
        "\n",
        "    if ch1_idx >= num_channels or ch2_idx >= num_channels:\n",
        "        raise ValueError(f\"Channel indices out of range. Data has {num_channels} channels.\")\n",
        "\n",
        "    print(f\"Computing synthetic channel (rotation difference) using channels {ch1_idx} ({channel_names[ch1_idx]}) and {ch2_idx} ({channel_names[ch2_idx]}).\")\n",
        "\n",
        "    integrated_ch1 = np.cumsum(data[ch1_idx].astype(float) * dt, axis=-1)\n",
        "    integrated_ch2 = np.cumsum(data[ch2_idx].astype(float) * dt, axis=-1)\n",
        "\n",
        "    synthetic_channel = np.abs(integrated_ch1 + integrated_ch2)\n",
        "\n",
        "    # Append the synthetic channel to the existing dataset.\n",
        "    updated_data = np.vstack([data, np.expand_dims(synthetic_channel, axis=0)])\n",
        "    channel_names.append(f\"Synthetic_RotationDiff_{channel_names[ch1_idx]}_{channel_names[ch2_idx]}\")\n",
        "\n",
        "    print(f\"New data shape after adding synthetic rotation difference channel: {updated_data.shape}\")\n",
        "    return updated_data, channel_names\n",
        "\n",
        "\n",
        "def create_autoencoder_model(input_shape):\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    x = Conv1D(32, kernel_size=3, activation=\"relu\", padding=\"same\")(input_layer)\n",
        "    x = MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = Conv1D(16, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "\n",
        "    # Bottleneck\n",
        "    x = Conv1D(8, kernel_size=3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = UpSampling1D(size=2)(x)\n",
        "    x = Conv1D(16, kernel_size=3, activation='relu', padding=\"same\")(x)\n",
        "    x = UpSampling1D(size=2)(x)\n",
        "    x = Conv1D(32, kernel_size=3, activation='relu', padding=\"same\")(x)\n",
        "\n",
        "    output_layer = Conv1D(input_shape[-1], kernel_size=3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    autoencoder.summary()\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "def permutation_importance_autoencoder(model, X, channel_names):\n",
        "\n",
        "    reconstructed_data = model.predict(X)\n",
        "    baseline_errors = np.mean(np.square(X - reconstructed_data), axis=(1, 2))\n",
        "    baseline_score = np.mean(baseline_errors)\n",
        "\n",
        "    importances = []\n",
        "    num_channels = X.shape[-1]\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        X_permuted = X.copy()\n",
        "        # Permute the data for channel i\n",
        "        X_permuted[:, :, i] = np.random.permutation(X_permuted[:, :, i])\n",
        "        reconstructed_permuted = model.predict(X_permuted)\n",
        "        permuted_errors = np.mean(np.square(X_permuted - reconstructed_permuted), axis=(1, 2))\n",
        "        permuted_score = np.mean(permuted_errors)\n",
        "\n",
        "        importance = permuted_score - baseline_score\n",
        "        importances.append(importance)\n",
        "        print(f\"Channel {i} ({channel_names[i]}) importance: {importance:.4f}\")\n",
        "\n",
        "    return importances\n",
        "\n",
        "def plot_importance_scores(importances, channel_names):\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(channel_names, importances, color='skyblue')\n",
        "    plt.xlabel(\"Channels\")\n",
        "    plt.ylabel(\"Increase in MSE (Permutation Importance)\")\n",
        "    plt.title(\"Channel Permutation Importances\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def normalize_data(data):\n",
        "\n",
        "    # Make a copy to avoid modifying the original data\n",
        "    normalized_data = data.copy()\n",
        "    num_channels = normalized_data.shape[-1]\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        channel_data = normalized_data[:, :, i]\n",
        "        min_val = np.min(channel_data)\n",
        "        max_val = np.max(channel_data)\n",
        "        if max_val - min_val > 0:\n",
        "            normalized_data[:, :, i] = (channel_data - min_val) / (max_val - min_val)\n",
        "        else:\n",
        "            normalized_data[:, :, i] = 0.0  # If no variation, set to 0\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def compute_input_distance(model, X_train, X_input):\n",
        "\n",
        "    # Compute reconstruction error on the training data\n",
        "    train_recon = model.predict(X_train)\n",
        "    train_error = np.mean(np.square(X_train - train_recon))\n",
        "\n",
        "    # Compute reconstruction error on the input data\n",
        "    input_recon = model.predict(X_input)\n",
        "    input_error = np.mean(np.square(X_input - input_recon))\n",
        "\n",
        "    print(\"\\n--- Input Distance Analysis ---\")\n",
        "    print(f\"Average reconstruction error on training data: {train_error:.4f}\")\n",
        "    print(f\"Average reconstruction error on input data:    {input_error:.4f}\")\n",
        "\n",
        "    if train_error > 0:\n",
        "        # Compute relative distance: (difference / training error)\n",
        "        distance_score = (input_error - train_error) / train_error\n",
        "        print(f\"Input distance score (relative to training data): {distance_score:.4f}\")\n",
        "    else:\n",
        "        distance_score = np.nan\n",
        "        print(\"Training error is zero; cannot compute a relative distance score.\")\n",
        "\n",
        "    return distance_score\n",
        "\n",
        "def choseChannelToCheck(model, X, channels_to_permute, channel_names):\n",
        "\n",
        "    # Compute baseline reconstruction error\n",
        "    baseline_recon = model.predict(X)\n",
        "    baseline_error = np.mean(np.square(X - baseline_recon))\n",
        "\n",
        "    # Permute specified channels together\n",
        "    X_permuted = X.copy()\n",
        "    for idx in channels_to_permute:\n",
        "        X_permuted[:, :, idx] = np.random.permutation(X_permuted[:, :, idx])\n",
        "\n",
        "    # Compute reconstruction error on the permuted data\n",
        "    permuted_recon = model.predict(X_permuted)\n",
        "    permuted_error = np.mean(np.square(X_permuted - permuted_recon))\n",
        "\n",
        "    error_difference = permuted_error - baseline_error\n",
        "    print(f\"\\nCombined Permutation of Channels {channels_to_permute} ({[channel_names[i] for i in channels_to_permute]})\")\n",
        "    print(f\"Baseline Reconstruction Error: {baseline_error:.4f}\")\n",
        "    print(f\"Permuted Reconstruction Error: {permuted_error:.4f}\")\n",
        "    print(f\"Error Increase: {error_difference:.4f}\")\n",
        "\n",
        "    # Plot the comparison\n",
        "    labels = ['Baseline', 'Permuted']\n",
        "    errors = [baseline_error, permuted_error]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(labels, errors, color=['skyblue', 'salmon'])\n",
        "    plt.ylabel(\"Reconstruction Error (MSE)\")\n",
        "    plt.title(f\"Combined Permutation Effect for Channels: {channels_to_permute}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return baseline_error, permuted_error, error_difference\n",
        "\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    github_user = \"usernameLoophole\"\n",
        "    repo_name_healthy = \"autoencoderDatasetHealthy\"\n",
        "    repo_name_injury = \"autoencoderDatasetInjury\"\n",
        "    N = 200\n",
        "    K = 0.5\n",
        "\n",
        "    # Load and preprocess healthy data\n",
        "    dataH, channel_names_H = load_and_preprocess(github_user, repo_name_healthy, N, K)\n",
        "    # Adjust the indices for the synthetic channel as needed:\n",
        "    trainData, channel_names_H = add_synthetic_channel(dataH, 11, 17, channel_names_H, 0.01)\n",
        "\n",
        "    # Load and preprocess injury data (or any new input data)\n",
        "    dataI, channel_names_I = load_and_preprocess(github_user, repo_name_injury, N, K)\n",
        "    testData, channel_names_I = add_synthetic_channel(dataI, 11, 17, channel_names_I, 0.01)\n",
        "\n",
        "    # Print final channel names\n",
        "    print(\"\\nFinal Healthy Dataset Channels:\", channel_names_H)\n",
        "    print(\"Final Injury Dataset Channels:\", channel_names_I)\n",
        "\n",
        "    # Train the autoencoder\n",
        "    num_channels = testData.shape[0]\n",
        "    autoencoder = create_autoencoder_model(input_shape=(N, num_channels))\n",
        "\n",
        "    # Reshape trainData and testData to match the expected input shape\n",
        "    # (num_windows, num_samples, num_channels)\n",
        "    trainData = trainData.transpose(1, 2, 0)\n",
        "    testData = testData.transpose(1, 2, 0)\n",
        "    print(\"trainData shape:\", trainData.shape)\n",
        "    print(\"testData shape:\", testData.shape)\n",
        "\n",
        "    # Normalize data channel-wise\n",
        "    trainData = normalize_data(trainData)\n",
        "    testData = normalize_data(testData)\n",
        "\n",
        "    autoencoder.fit(trainData, trainData, epochs=20, batch_size=32, validation_data=(testData, testData))\n",
        "\n",
        "    # Compute and report how \"distant\" the input is compared to training data\n",
        "    distance_score = compute_input_distance(autoencoder, trainData, testData)\n",
        "\n",
        "    # Compute feature importance for each channel using the test dataset\n",
        "    importance_scores = permutation_importance_autoencoder(autoencoder, testData, channel_names_I)\n",
        "    print(\"Feature Importances:\", importance_scores)\n",
        "\n",
        "    # Plot the permutation importance scores\n",
        "    plot_importance_scores(importance_scores, channel_names_I)\n",
        "\n",
        "    # Now, use choseChannelToCheck to evaluate the combined effect of permuting two channels together.\n",
        "    combined_channels = [9, 15]\n",
        "    choseChannelToCheck(autoencoder, testData, combined_channels, channel_names_I)\n"
      ]
    }
  ]
}